\section{Research Gap and Project Objectives}

Existing literature explores different kinds of fault tolerance within specialized software systems, both in hardware and software. Papers tend to have a narrow focus, either on the operational or the developmental phase, and do not present a general applicability regardless of the domain.

The goal for this paper is to enable the direct comparison of strengths and weaknesses within approximate computing methods that are implemented in tools or frameworks. 


Measuring both operational and developmental fault tolerance is important to get the full picture of how a system behaves.
To properly gauge {\em developmental fault tolerance}, we can use G-SWFIT~\citep{duraes2006emulation}. G-SWFIT can be used to inject faults that are representative for software in general (faults that appear in real world production code, and that is missed by the test suite). Importantly, \citet{natella2012fault} makes the point that using fault types that represent the occurrence of faults in the real world is vital for making a trustworthy evaluation of fault tolerance. With all the progress that has been made in the programming world since 2013, especially regarding AI code generation, it is therefore important to verify that the fault categories mentioned are still representative.

{\em Operational faults} can be injected at runtime using Gem5-Approxilyzer~\citep{venkatagiri2019gem5}, this to gain an overview of how changes in the code affect the reliability of the finished executable. This tool allows the user to follow how operational errors propagate throughout the code unlike anything that can practically be performed only in hardware.



\subsection{How to measure fault tolerance}
Measuring fault tolerance is done through the concept of coverage. Coverage refers to the degree in which errors are detected, and how well the system recovers from these errors.

Measuring fault tolerance in approximate computing requires some extra considerations:
\begin{enumerate}
    \item  In approximate computing techniques, not all parts of the system is approximate; for example in loop perforation, only the loop is affected, precision scaling only operates on certain variables that exist in certain contexts, etc.
    \item Not only operational faults may affect the approximate parts differently, but also the developmental faults. The literature does not cover whether developmental faults have a greater effect on approximate computing systems than precise computing systems. 
\end{enumerate}


There are many metrics in the studies that have previously been mentioned that can be applied for approximate computing applications. In addition to using preexisting metrics, the project will explore new metrics to gauge different aspects of fault tolerance within approximate computing.  

  The project will include performing mutation testing to evaluate a test suite. The mutation testing will be performed using \citet{papadakis2019mutation} as a guide, to evaluate whether the approximate computing strategies have different effects on a test suite.


To see the effect that the approximate blocks have on the rest of the system the project will include injecting faults in the code blocks that contain approximate constructs: 
$$\frac{\text{faults that cause error in approximate block}}{\text{faults that create errors that propagate to the result}}$$
This will be measured both with operational faults through the gem5-approxilyzer\citep{venkatagiri2019gem5}, as well as with injected software faults. 


These metrics will be used in combination with the G-SWFIT technique for injection of representative faults\citep{duraes2006emulation}.
This is not an exhaustive list. As the project progresses additional metrics may be developed.


One thing that these metrics lack, is the ability to directly compare between different methods of approximate computing. This stems from the fact even though source code for different types of approximate computing may be similar, in practice faults may affect similar source code locations in very different ways. 

A goal for the project is therefore to combine and revise existing metrics to allow for better comparisons between approximate computing systems, providing researchers and developers with an overview of the reliability of an approximate computing tool in addition to performance and energy efficiency.  
